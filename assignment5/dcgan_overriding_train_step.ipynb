{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWtxwZZV7aIG"
   },
   "source": [
    "# DCGAN to generate face images\n",
    "\n",
    "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
    "**Date created:** 2019/04/29<br>\n",
    "**Last modified:** 2021/01/01<br>\n",
    "**Description:** A simple DCGAN trained using `fit()` by overriding `train_step` on CelebA images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4McCfU8-7aIJ"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6J2bUdEI7aIJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import gdown\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "12Z5nLem7aIK"
   },
   "source": [
    "## Prepare CelebA data\n",
    "\n",
    "We'll use face images from the CelebA dataset, resized to 64x64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m0_M8aew7aIK"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"celeba_gan\")\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
    "output = \"celeba_gan/data.zip\"\n",
    "gdown.download(url, output, quiet=True)\n",
    "\n",
    "with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
    "    zipobj.extractall(\"celeba_gan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnDksPYX7aIK"
   },
   "source": [
    "Create a dataset from our folder, and rescale the images to the [0-1] range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "egcgtCya7aIK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 202599 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=32\n",
    ")\n",
    "dataset = dataset.map(lambda x: x / 255.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwS32qE_7aIL"
   },
   "source": [
    "Let's display a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nWzH3gB27aIM"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow((x.numpy() * 255).astype(\"int32\")[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MOXNagp07aIM"
   },
   "source": [
    "## Create the discriminator\n",
    "\n",
    "It maps a 64x64 image to a binary classification score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dolL5PHm7aIN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 64)        3136      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 16, 16, 128)       131200    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 128)         262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 404,801\n",
      "Trainable params: 404,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(64, 64, 3)),\n",
    "        layers.Conv2D(64, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"discriminator\",\n",
    ")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cj_-iJKG7aIN"
   },
   "source": [
    "## Create the generator\n",
    "\n",
    "It mirrors the discriminator, replacing `Conv2D` layers with `Conv2DTranspose` layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "6or9UDg47aIN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8192)              1056768   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 16, 16, 128)       262272    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       524544    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 512)       2097664   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 3)         38403     \n",
      "=================================================================\n",
      "Total params: 3,979,651\n",
      "Trainable params: 3,979,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "\n",
    "generator = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(latent_dim,)),\n",
    "        layers.Dense(8 * 8 * 128),\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "        layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.Conv2D(3, kernel_size=5, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ],\n",
    "    name=\"generator\",\n",
    ")\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPK7UK7L7aIN"
   },
   "source": [
    "## Override `train_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8TWPqLTl7aIO"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GAN(keras.Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(GAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
    "        super(GAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
    "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.d_loss_metric, self.g_loss_metric]\n",
    "\n",
    "    def train_step(self, real_images):\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            d_loss = self.loss_fn(labels, predictions)\n",
    "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
    "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Update metrics\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            \"d_loss\": self.d_loss_metric.result(),\n",
    "            \"g_loss\": self.g_loss_metric.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0wyi0ko67aIO"
   },
   "source": [
    "## Create a callback that periodically saves generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xymlkCFz7aIP"
   },
   "outputs": [],
   "source": [
    "\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = keras.preprocessing.image.array_to_img(generated_images[i])\n",
    "            img.save(\"generated_img_%03d_%d.png\" % (epoch, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HiGPEetq7aIP"
   },
   "source": [
    "## Train the end-to-end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "AkZyY8QI7aIP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 455/6332 [=>............................] - ETA: 8:02 - d_loss: 0.4986 - g_loss: 1.3655"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8ff49bb57b5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m gan.fit(\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGANMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_img\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m )\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf_env/tf_env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 1  # In practice, use ~100 epochs\n",
    "\n",
    "gan = GAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
    ")\n",
    "\n",
    "gan.fit(\n",
    "    dataset, epochs=epochs, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oIl8CIh7aIP"
   },
   "source": [
    "Some of the last generated images around epoch 30\n",
    "(results keep improving after that):\n",
    "\n",
    "![results](https://i.imgur.com/h5MtQZ7l.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_overriding_train_step",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
